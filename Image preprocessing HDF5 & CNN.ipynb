{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5136c2df1fa148298432d1ecfacf3af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "label_list = []\n",
    "for root, dirs, files in tqdm_notebook(os.walk(\"frame_images_DB\")):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\"):\n",
    "            label_list.append(root.split('/')[1])\n",
    "#             print(root.split('/')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5b2f61bbbf4cd3907795b272ab099a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# list number of folders contain frames\n",
    "test_list = list(set(label_list))\n",
    "folder_set = set()\n",
    "for root, dirs, files in tqdm_notebook(os.walk(\"frame_images_DB\")):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\"):\n",
    "            name = root.split('/')[1]            \n",
    "            if name in test_list:\n",
    "                folder_set.add(root)\n",
    "                test_list.remove(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1595"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folder_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select frames, 48 per person\n",
    "import random\n",
    "file_list = []\n",
    "for path in folder_set:\n",
    "    file = random.sample(os.listdir(path),48)\n",
    "    for i in file:\n",
    "        file_list.append(path+'/'+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76560"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frame_images_DB/Laurie_Laychak/0/0.750.jpg'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split file path into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_addrs,test_addrs = train_test_split(file_list, test_size = 0.2, random_state = 1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61248"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_addrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate shape\n",
    "train_shape = (len(train_addrs), 24, 24, 3)\n",
    "test_shape = (len(test_addrs), 24, 24, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate labels\n",
    "train_labels = [i.split('/')[1] for i in train_addrs]\n",
    "test_labels = [i.split('/')[1] for i in test_addrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"test_img\": shape (15312, 24, 24, 3), type \"|i1\">"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize hdf5\n",
    "import numpy as np\n",
    "import h5py\n",
    "hdf5_path = 'dataset.hdf5'\n",
    "hdf5_file = h5py.File(hdf5_path, mode='w')\n",
    "hdf5_file.create_dataset(\"train_img\", train_shape, np.int8)\n",
    "hdf5_file.create_dataset(\"test_img\", test_shape, np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file.create_dataset(\"train_mean\", train_shape[1:], np.float32)\n",
    "dt = h5py.special_dtype(vlen=str) \n",
    "hdf5_file.create_dataset(\"train_labels\", (len(train_addrs),), dt)\n",
    "hdf5_file[\"train_labels\"][...] = train_labels\n",
    "hdf5_file.create_dataset(\"test_labels\", (len(test_addrs),), dt)\n",
    "hdf5_file[\"test_labels\"][...] = test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072b077d3a114eb08627baee91d5328a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61248), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b54c29edc94b92982cd45f7c6cc036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "# a numpy array to save the mean of the images\n",
    "mean = np.zeros(train_shape[1:], np.float32)\n",
    "# loop over train addresses\n",
    "for i in tqdm_notebook(range(len(train_addrs))):\n",
    "    # read an image and resize to (24, 24)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = train_addrs[i]\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.resize(img, (24, 24), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # add any image pre-processing here\n",
    "\n",
    "    # save the image and calculate the mean so far\n",
    "    hdf5_file[\"train_img\"][i, ...] = img[None]\n",
    "    mean += img / float(len(train_labels))\n",
    "\n",
    "# loop over test addresses\n",
    "for i in tqdm_notebook(range(len(test_addrs))):\n",
    "    # read an image and resize to (24, 24)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = test_addrs[i]\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.resize(img, (24, 24), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # add any image pre-processing here\n",
    "\n",
    "    # save the image\n",
    "    hdf5_file[\"test_img\"][i, ...] = img[None]\n",
    "# save the mean and close the hdf5 file\n",
    "hdf5_file[\"train_mean\"][...] = mean\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "hdf5_path = 'dataset.hdf5'\n",
    "subtract_mean = False\n",
    "# open the hdf5 file\n",
    "hdf5_file = h5py.File(hdf5_path, \"r\")\n",
    "# subtract the training mean\n",
    "if subtract_mean:\n",
    "    mm = hdf5_file[\"train_mean\"][0, ...]\n",
    "    mm = mm[np.newaxis, ...]\n",
    "# Total number of samples\n",
    "data_num = hdf5_file[\"train_img\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABgAAAAYCAIAAABvFaqvAAADb0lEQVR4nK2Uf4gUZRjHH1/fXl+GcXgdpmFdpr3lutuW5ViOcxURCcvN4vKCusDTo1Ix748sEZQzLAMJMrsgkrQfFISdXCZ2KnngaSRKXSLXIccRsq7XtizbMq7TMAzj29t7/XGbpjftRfj+9Tzvl/fzfr/PC++cqakpuBcL3RPK7KD585t7X3/7v4Dm1In2UkdnvEnVY3EFs7Uvb/ufjjasfDqdQClaWZ2wlrfp/e8erA/Cf8Cf98HcmYLgeWErnkJztqtVtfbW5CyOLvz4fagguJKrivG8D9xWmeSyNIujRsMKByFJA1+Vbn7k0sCVI00GWW7DorXd/+posjgWKrRSJqjd1maVK/a6bMZKZBYtTddxhDCOhgqF6oQrcLlSeHRZerIw0fnM6pOHT9QDMRr+cKn0Ksq1i1f8wuR4qQr73z/QsWtXPdD4+M+hwtZDn7qIIKKXKgFEoyvau+pQAACrZuRW89uv19Zv3GKjAIMXoRh7DgdOXakT98zRYzs/HvRADA58sWDhwhBHVozdaro2rxsa/oZVCEY6lWpcMV0PBKJGxDQb4xozzp07u3nLa+HRGLsN0hQGAMM/DVGMGbGoBlHTzJX4hZH8aNHe17cbACQqhoPw37N+49W3iFZrkprKcNEgJBnRVUPRowyI8UDzQwCgK8YjT3aGgAhWp6uLY6NC1twV8zKlcKQGiE6mGI+zSHs2WxuqpPo/QtwGqUyfrgxVcmx/3rsDANJLV6UyCTPZoslYVDcV5li4lsgBTpGYCap9Iz3dPZz4JsLPPhwzT+cb+g+d7/+oMbBtu+r4ZTXSaMWWfFtJLqvm+i4ddigKOPmq/5M7HNXuwXLv7p1PtSDDcxtWJACg78MxwzJjiXjrkmwiqhs6GTzyWUNLZs/zmxDHWFPvjgZw85er157IJC+ferMp0cosC6gKAMfPH8xhHdEWzqhD44Ijg8Th8fsXqKUDr7THOP566Ie7QPP69r0nvbLiSM8ruKJ8XQtuvvgOAOzZ+x0gV3BCwBci+OB4DwCAqxIptm/Mnjo6MCMaIkrge4KXi1XkAPdhnq4BwJfD+09MICJARdrIqF87IangCoiAKPIO0IPNi4E4GiogKami+V5F2AHo5Wn5uW0dRdLZ1HV65Y41tRMdj0lZ9rx8W9LqfqH39+s3prf/Aos0TMb8IO07AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=24x24 at 0x11FD30518>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import array_to_img\n",
    "img_test = array_to_img(hdf5_file[\"train_img\"][0])\n",
    "img_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61248"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 22, 22, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 20, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               819328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1595)              205755    \n",
      "=================================================================\n",
      "Total params: 1,044,475\n",
      "Trainable params: 1,044,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      " - 55s - loss: 7.7315 - acc: 0.0011\n",
      "Epoch 2/3\n",
      " - 54s - loss: 7.3479 - acc: 0.0038\n",
      "Epoch 3/3\n",
      " - 56s - loss: 7.1110 - acc: 0.0160\n"
     ]
    }
   ],
   "source": [
    "# convert labels to OHE\n",
    "from keras import utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(hdf5_file[\"train_labels\"])\n",
    "encoded_train = encoder.transform(hdf5_file[\"train_labels\"])\n",
    "encoded_test = encoder.transform(hdf5_file[\"test_labels\"])\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_train = utils.to_categorical(encoded_train)\n",
    "dummy_test = utils.to_categorical(encoded_test)\n",
    "\n",
    "\n",
    "# Build NN Structure\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import optimizers\n",
    "\n",
    "batch_size = 1280\n",
    "num_classes = dummy_train.shape[1]\n",
    "epochs = 3\n",
    "input_shape = (24, 24, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation ='relu',\n",
    "                 input_shape =input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "history1 = model.fit(hdf5_file[\"train_img\"], dummy_train,\n",
    "                     batch_size = batch_size,\n",
    "                     epochs = epochs,\n",
    "                     verbose = 2,\n",
    "                     shuffle = 'batch'\n",
    "                     )\n",
    "                     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
